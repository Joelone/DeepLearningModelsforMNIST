{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#Load MNIST dataset\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADy9JREFUeJzt3X+wVPV5x/HPA14BURLRlhIkQRRr0EFkLmgbm5AhWgNY\ntZlanU5CZ6w3yWimdEgbhzatfzVMJkqISTSoJFitP6ZKNBGjllqtDVKviiiiYs11gLmAiApa5ce9\nT/+4h8wV7/nusnt2z16e92vmzt09z549j0c+9+zud8/5mrsLQDxDym4AQDkIPxAU4QeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoI5o5saOtGE+XCObuUkglA/0nvb6HqvmsXWF38zOl7RE0lBJN7v7otTj\nh2ukzrJZ9WwSQMIaX1X1Y2t+2W9mQyX9SNIXJU2WdJmZTa71+QA0Vz3v+WdIetXdX3P3vZLulHRh\nMW0BaLR6wj9O0qZ+9zdnyz7EzDrMrNPMOvdpTx2bA1Ckhn/a7+5L3b3d3dvbNKzRmwNQpXrCv0XS\n+H73T8iWARgE6gn/U5ImmdmJZnakpEsl3V9MWwAareahPnffb2ZXSXpIfUN9y9x9fWGdAWiousb5\n3X2lpJUF9QKgifh6LxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrw\nA0HVNUuvmXVJ2i2pR9J+d28voikMHnvmTE/Wd17xbm7t2em3F93Oh3xt8x/l1p548IzkuhN/8lqy\nvr97a009tZK6wp/5vLvvKOB5ADQRL/uBoOoNv0t62MyeNrOOIhoC0Bz1vuw/x923mNnvSnrEzF5y\n98f7PyD7o9AhScN1VJ2bA1CUuo787r4l+71d0gpJMwZ4zFJ3b3f39jYNq2dzAApUc/jNbKSZHXPg\ntqTzJL1QVGMAGquel/1jJK0wswPP86/u/qtCugLQcObuTdvYKBvtZ9mspm0PlVnbkcn6K9edmaw/\ncMHiZP3ktvLe6g2R5dZ6lf53P/XJryTrJ3xpfU09NdoaX6VdvjP/P7wfhvqAoAg/EBThB4Ii/EBQ\nhB8IivADQRVxVh8GsZevn5qsv3LBj5P1IRqerFcaUqtHx6aZyfrN4x+r+bl/MPXOZP3a4z6XrPe8\nubPmbTcLR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/sNA6rTcSuP46+f+sMKzD01Wu3v+L1n/\n7Ipv5tYmrtibXHfYxvTlsXt2vJmsn3nXX+TWnp5+W3LdZ96fkKz73n3J+mDAkR8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgmKc/zDQfWX+zOivXHB9hbXT4/i3vPPJZP3eK85N1if995MVtp9vf81r9tmz\np63mdX+xZUqyPmL3b2p+7lbBkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqo4zm9myyTNlbTd3U/P\nlo2WdJekCZK6JF3i7m81rk2kfL3jvtxaappqSfrOm5OT9dV/ckqybl1rk/V6DB01Klnf/FenJ+t/\nN+Xe3Nqze3uT647448E/jl9JNUf+n0k6/6BlV0ta5e6TJK3K7gMYRCqG390fl3Tw9CMXSlqe3V4u\n6aKC+wLQYLW+5x/j7t3Z7a2SxhTUD4AmqfsDP3d3KX9CNjPrMLNOM+vcpz31bg5AQWoN/zYzGytJ\n2e/teQ9096Xu3u7u7W0aVuPmABSt1vDfL2lednuepPyPmwG0pIrhN7M7JK2W9PtmttnMLpe0SNK5\nZrZR0hey+wAGkYrj/O5+WU5pVsG9oEY9ib/hvfkfx0iSVv7zzGT9mK7az8eXJA3Jv15Az+fOSK46\n94erkvWvffzR9KYT33GY83KlAaotFeqDH9/wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbuDO2preprs\neqWG8x687aaGbvviV2fn1oZ8KT21eE/RzbQgjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/IeB\nje8nLqH4sa7kustu/UGyvmjbF5L1/3z95GT9VzNSzz8iue47vR8k69Mf+Jtk/dQF63Nrve+9l1w3\nAo78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxCU9c221RyjbLSfZVzxu3BnT8kt/fKenzZ005WmAK90\n6fCUaUu+kax/4ru/rvm5D1drfJV2+c70/5QMR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKri+fxm\ntkzSXEnb3f30bNk1kq6Q9Eb2sIXuvrJRTUa3Z870ZH3Tpftza5XG4es11CocP7w3tzRr/Z8mV2Uc\nv7GqOfL/TNL5Ayxf7O5Tsx+CDwwyFcPv7o9L2tmEXgA0UT3v+a8ys3VmtszMji2sIwBNUWv4b5B0\nkqSpkrolXZv3QDPrMLNOM+vcpz01bg5A0WoKv7tvc/ced++VdJOkGYnHLnX3dndvb9OwWvsEULCa\nwm9mY/vdvVjSC8W0A6BZqhnqu0PSTEnHm9lmSf8kaaaZTZXkkrokfbWBPQJoAM7nb4IhU05N1n9v\n6ZZk/ebxjyXr9ZwzX8nVW9PfMbj3f9qT9RvOXZ5bm9T2ZnLdr/ztN5P1o+9+MlmPiPP5AVRE+IGg\nCD8QFOEHgiL8QFCEHwiKob4C7Oj4g2T9oW9/L1n/2JDhyXo9l8de0H12ct0H/yM9VHfK4t8k6/u7\ntybrPZ+flr/t225Krnvj2xOT9V+exiklB2OoD0BFhB8IivADQRF+ICjCDwRF+IGgCD8QVMXz+dFn\n96X54+X1juNv2LcvWV+89dxk/eXvn5a/7Z+vTa478YPVyXr+RcGrM/Sx53Jrp959ZXLd5/7s+8n6\nivOuStbbHu5M1qPjyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOX6UdU/JPka40jr/ivdHJ+k8v\nmZOs9659MVk/RvmXsM6fILs5hozI3zenTetKrjvM2pL13iMaO/344Y4jPxAU4QeCIvxAUIQfCIrw\nA0ERfiAowg8EVXGc38zGS7pV0hhJLmmpuy8xs9GS7pI0QVKXpEvc/a3Gtdq6Kl1X/1uPXpKsn7L2\nqSLbaaqhxx+XrB+1In/f3DVxZYVnZxy/kao58u+XtMDdJ0s6W9KVZjZZ0tWSVrn7JEmrsvsABomK\n4Xf3bnd/Jru9W9IGSeMkXShpefaw5ZIualSTAIp3SO/5zWyCpDMlrZE0xt27s9JW9b0tADBIVB1+\nMzta0j2S5rv7rv4175vwb8AJ48ysw8w6zaxzn/bU1SyA4lQVfjNrU1/wb3f3e7PF28xsbFYfK2n7\nQOu6+1J3b3f39jYNK6JnAAWoGH4zM0m3SNrg7tf1K90vaV52e56k+4pvD0CjVHNK72ckfVnS82Z2\n4DrQCyUtknS3mV0u6XVJ6fGsQe74dfnTYL/V+35y3admpy9BPf0n85P1T//j68l6z7YBX3RV5Yhx\nn0jW3ztjXLI+f8kdyfqco97JrVU63fhHb5+UrI/4r5eS9bJPZ251FcPv7k8of8B1VrHtAGgWvuEH\nBEX4gaAIPxAU4QeCIvxAUIQfCMr6vpnbHKNstJ9lh9/o4KZ/+MNk/bmvX1/X86/fm54oe/7GP6/5\nuf/t07cn65UuS17pdObegb/1LUla0J0/7bkkvfSNycm6rc6f/juqNb5Ku3xnVedCc+QHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaCYorsAo1/qSdZvfHtisj55+OZkfebw9LDtI6fdk6ynpcfxK7nxnU8l\n64sfmJtbm/TtZ5Pr2geM4zcSR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrz+VvAERM+maxvXPTx\nmp/7O9N+nqz/evfJyfovHjorWT9x4epD7gmNw/n8ACoi/EBQhB8IivADQRF+ICjCDwRF+IGgKo7z\nm9l4SbdKGiPJJS119yVmdo2kKyS9kT10obuvTD0X4/xAYx3KOH81F/PYL2mBuz9jZsdIetrMHslq\ni939e7U2CqA8FcPv7t2SurPbu81sg6RxjW4MQGMd0nt+M5sg6UxJa7JFV5nZOjNbZmbH5qzTYWad\nZta5T3vqahZAcaoOv5kdLekeSfPdfZekGySdJGmq+l4ZXDvQeu6+1N3b3b29TcMKaBlAEaoKv5m1\nqS/4t7v7vZLk7tvcvcfdeyXdJGlG49oEULSK4Tczk3SLpA3ufl2/5WP7PexiSS8U3x6ARqnm0/7P\nSPqypOfNbG22bKGky8xsqvqG/7okfbUhHQJoiGo+7X9CGnAS9uSYPoDWxjf8gKAIPxAU4QeCIvxA\nUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTV1im4ze0PS6/0WHS9pR9MaODSt\n2lur9iXRW62K7O1T7v471TywqeH/yMbNOt29vbQGElq1t1btS6K3WpXVGy/7gaAIPxBU2eFfWvL2\nU1q1t1btS6K3WpXSW6nv+QGUp+wjP4CSlBJ+MzvfzF42s1fN7OoyeshjZl1m9ryZrTWzzpJ7WWZm\n283shX7LRpvZI2a2Mfs94DRpJfV2jZltyfbdWjObXVJv483sUTN70czWm9lfZ8tL3XeJvkrZb01/\n2W9mQyW9IulcSZslPSXpMnd/samN5DCzLknt7l76mLCZfVbSu5JudffTs2XflbTT3RdlfziPdfdv\ntUhv10h6t+yZm7MJZcb2n1la0kWS/lIl7rtEX5eohP1WxpF/hqRX3f01d98r6U5JF5bQR8tz98cl\n7Txo8YWSlme3l6vvH0/T5fTWEty9292fyW7vlnRgZulS912ir1KUEf5xkjb1u79ZrTXlt0t62Mye\nNrOOspsZwJhs2nRJ2ippTJnNDKDizM3NdNDM0i2z72qZ8bpofOD3Uee4+zRJX5R0ZfbytiV533u2\nVhquqWrm5mYZYGbp3ypz39U643XRygj/Fknj+90/IVvWEtx9S/Z7u6QVar3Zh7cdmCQ1+7295H5+\nq5Vmbh5oZmm1wL5rpRmvywj/U5ImmdmJZnakpEsl3V9CHx9hZiOzD2JkZiMlnafWm334fknzstvz\nJN1XYi8f0iozN+fNLK2S913LzXjt7k3/kTRbfZ/4/6+kvy+jh5y+Jkp6LvtZX3Zvku5Q38vAfer7\nbORyScdJWiVpo6R/lzS6hXr7F0nPS1qnvqCNLam3c9T3kn6dpLXZz+yy912ir1L2G9/wA4LiAz8g\nKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9P5Y+soSlkI5gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21e72de3ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[5].reshape([28, 28]))\n",
    "print(mnist.train.labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tr = mnist.train.images.shape[0]# number of training samples\n",
    "n_ts = mnist.test.images.shape[0]#number of testing samples\n",
    "n_pixel = mnist.train.images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_norm_cnn = tf.Graph()\n",
    "with batch_norm_cnn.as_default() as g:\n",
    "    #Create input placeholders\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, [None,10])\n",
    "    #Define ropout probability placholder\n",
    "    keep_prob = tf.placeholder(\"float\")   \n",
    "\n",
    "    y = bn_cnnLayer(x, keep_prob)\n",
    "    #Define cross-entropy as loss function\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "    #RMSprop Optimizer\n",
    "    train_step = optimize_method('rmsprop', cross_entropy)\n",
    "    #Define accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below code was referred to http://danijar.com/structuring-your-tensorflow-models/\n",
    "import functools\n",
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator decorator, allowing to use the decorator to be used without\n",
    "    parentheses if not arguments are provided. All arguments must be optional.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@doublewrap\n",
    "def define_scope(function, scope=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    A decorator for functions that define TensorFlow operations. The wrapped\n",
    "    function will only be executed once. Subsequent calls to it will directly\n",
    "    return the result so that operations are added to the graph only once.\n",
    "\n",
    "    The operations added by the function live within a tf.variable_scope(). If\n",
    "    this decorator is used with arguments, they will be forwarded to the\n",
    "    variable scope. The scope name defaults to the name of the wrapped\n",
    "    function.\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__#Get function name\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)#Keep the original function\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):#If the attribute not exist\n",
    "            with tf.variable_scope(name, *args, **kwargs):#Add scope name\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)#otherwise return the attribute\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义一个MNIST分类的基类\n",
    "class MnistModel:\n",
    "    '''Define a basic model for MNIST image classification, the model\n",
    "    Provides graph structure of tensorflow'''\n",
    "    \n",
    "    def __init__(self, input_holder, target_holder, is_training, keep_prob):\n",
    "        self.input_holder = input_holder\n",
    "        self.target_holder = target_holder\n",
    "        self.is_training = is_training\n",
    "        self.num_pixel = 784\n",
    "        self.num_class = 10\n",
    "        self.keep_prob = keep_prob\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.accuracy\n",
    "        print('Initializing Mnist Model!') \n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        return None\n",
    "    \n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        return None\n",
    "    \n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.training import moving_averages\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "class CnnMnistModel(MnistModel):\n",
    "    #重构某些函数\n",
    "    \n",
    "    @define_scope(initializer=tf.contrib.slim.xavier_initializer())\n",
    "    def prediction(self):\n",
    "        #定义权重和偏置参数变量\n",
    "        logits = self.cnnLayer\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target_holder*\n",
    "                                       tf.log(self.prediction))\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @define_scope\n",
    "    def accuracy(self):\n",
    "        correct_prediction = tf.equal(tf.argmax(self.target_holder,1), \n",
    "                                      tf.argmax(self.prediction,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        return accuracy\n",
    "    \n",
    "    @define_scope\n",
    "    def cnnLayer(self):\n",
    "        x_image = tf.reshape(self.input_holder, [-1,28,28,1])\n",
    "        #First Conv\n",
    "        with tf.variable_scope('hidden'):\n",
    "            kernel_shape, bias_shape = [5, 5, 1, 32], [32] \n",
    "            h_pool1 = self.conv_relu_bn_pool(x_image, kernel_shape, bias_shape)\n",
    "            #Second Conv\n",
    "        with tf.variable_scope('hidden', reuse=True):\n",
    "            kernel_shape, bias_shape = [5, 5, 32, 64], [64] \n",
    "            h_pool2 = self.conv_relu_bn_pool(h_pool1, kernel_shape, bias_shape)\n",
    "    \n",
    "        #Fully Connected Layer\n",
    "        with tf.name_scope('fully_connected'):\n",
    "            W_fc1 = self.weight_variable([7 * 7 * 64, 1024])\n",
    "            b_fc1 = self.bias_variable([1024])\n",
    "            h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        #Dropout, to prevent against overfitting      \n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        #Softmax Layer\n",
    "        with tf.name_scope('softmax_layer'):\n",
    "            W_fc2 = weight_variable([1024, 10])\n",
    "            b_fc2 = bias_variable([10])\n",
    "            logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "            \n",
    "        return tf.nn.softmax(logits)\n",
    "    \n",
    "    #卷积函数\n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    #池化函数\n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    #Create weights\n",
    "    def weight_variable(self, shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial, name='weights')\n",
    "\n",
    "    #Create biases\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.constant(0.01, shape=shape)\n",
    "        return tf.Variable(initial, name='biases')\n",
    "    \n",
    "\n",
    "    def _get_variable(self, name,\n",
    "                  shape,\n",
    "                  initializer,\n",
    "                  weight_decay=0.0,\n",
    "                  dtype='float',\n",
    "                  trainable=True):\n",
    "        \"A little wrapper around tf.get_variable to do weight decay and add to\"\n",
    "        \"resnet collection\"\n",
    "        if weight_decay > 0:\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "        else:\n",
    "            regularizer = None\n",
    "            collections = [tf.GraphKeys.VARIABLES, \"batch_norm_variables\"]\n",
    "            \n",
    "        return tf.get_variable(name,\n",
    "                           shape=shape,\n",
    "                           initializer=initializer,\n",
    "                           dtype=dtype,\n",
    "                           regularizer=regularizer,\n",
    "                           collections=collections,\n",
    "                           trainable=trainable)\n",
    "\n",
    "    def conv_relu_bn_pool(self, x, kernel_shape, bias_shape):\n",
    "        # Create variable named \"weights\".\n",
    "        weights = self.weight_variable(kernel_shape)\n",
    "        # Create variable named \"biases\".\n",
    "        biases = self.bias_variable(bias_shape)\n",
    "        conv = self.conv2d(x, weights)\n",
    "        bn = self.batch_normlization(conv)\n",
    "        relu = tf.nn.relu(bn + biases)\n",
    "        pool = self.max_pool_2x2(relu)\n",
    "        return pool\n",
    "    \n",
    "    @define_scope\n",
    "    def batch_normlization(self, x):\n",
    "        x_shape = x.get_shape()\n",
    "        params_shape = x_shape[-1:]\n",
    "        axis = list(range(len(x_shape) - 1))\n",
    "        beta = _get_variable('beta',\n",
    "                             params_shape,\n",
    "                             initializer=tf.zeros_initializer)\n",
    "        gamma = _get_variable('gamma',\n",
    "                              params_shape,\n",
    "                              initializer=tf.ones_initializer)\n",
    "        moving_mean = _get_variable('moving_mean',\n",
    "                                    params_shape,\n",
    "                                    initializer=tf.zeros_initializer,\n",
    "                                    trainable=False)\n",
    "        moving_variance = _get_variable('moving_variance',\n",
    "                                    params_shape,\n",
    "                                    initializer=tf.ones_initializer,\n",
    "                                    trainable=False)  \n",
    "        # These ops will only be preformed when training.\n",
    "\n",
    "        mean, variance = tf.nn.moments(x, axis)\n",
    "\n",
    "        update_moving_mean = moving_averages.assign_moving_average(moving_mean,\n",
    "                                                               mean, 0.9997)\n",
    "        update_moving_variance = moving_averages.assign_moving_average(\n",
    "\n",
    "        moving_variance, variance, 0.9997)\n",
    "\n",
    "        tf.add_to_collection(\"UPDATE_OPS_COLLECTION\", update_moving_mean)\n",
    "\n",
    "        tf.add_to_collection(\"UPDATE_OPS_COLLECTION\", update_moving_variance)\n",
    "        \n",
    "        if self.is_training:\n",
    "            mean, variance = mean, variance\n",
    "        else:\n",
    "            mean, variance = moving_mean, moving_variance\n",
    "    \n",
    "\n",
    "        x = tf.nn.batch_normalization(x, mean, variance, beta, gamma, 0.001)\n",
    "        #x.set_shape(inputs.get_shape()) ??\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_normlization() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-4ca857309c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#输入数据对应标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtarget_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCnnMnistModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_holder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_holder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-44f50d5db830>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_holder, target_holder, is_training, keep_prob)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d65e7ab6eacc>\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#If the attribute not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Add scope name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#otherwise return the attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c6ff5f86afce>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[1;31m#定义权重和偏置参数变量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnnLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d65e7ab6eacc>\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#If the attribute not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Add scope name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#otherwise return the attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c6ff5f86afce>\u001b[0m in \u001b[0;36mcnnLayer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidden'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mkernel_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mh_pool1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_relu_bn_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[1;31m#Second Conv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidden'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c6ff5f86afce>\u001b[0m in \u001b[0;36mconv_relu_bn_pool\u001b[0;34m(self, x, kernel_shape, bias_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mbiases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mbn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normlization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mrelu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool_2x2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d65e7ab6eacc>\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#If the attribute not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Add scope name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#otherwise return the attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: batch_normlization() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "batch_size = 64\n",
    "num_pixel = 784\n",
    "num_class = 10\n",
    "#定义feed数据\n",
    "#定义输入数据\n",
    "data_holder = tf.placeholder(tf.float32, [None, num_pixel])\n",
    "#输入数据对应标签\n",
    "target_holder = tf.placeholder(tf.float32, [None,num_class])\n",
    "cnn_model = CnnMnistModel(data_holder, target_holder, True, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
